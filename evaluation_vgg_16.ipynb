{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import operator\n",
    "import sys\n",
    "import argparse\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "MINOVERLAP = 0.5 # default value (defined in the PASCAL VOC2012 challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/purva/Desktop/purva/ssd\n"
     ]
    }
   ],
   "source": [
    "cd /home/purva/Desktop/purva/ssd/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore = []\n",
    "\n",
    "specific_iou_flagged = False\n",
    "set_class_iou= None\n",
    "no_animation = True\n",
    "show_animation=False\n",
    "import matplotlib.pyplot as plt\n",
    "draw_plot = True\n",
    "no_plot = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/purva/Desktop/purva/ssd'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "GT_PATH = os.path.join(os.getcwd(), 'input', 'ground_truth')\n",
    "DR_PATH = os.path.join(os.getcwd(), 'input', 'detection_results')\n",
    "IMG_PATH = '/home/purva/Desktop/purva/Single_shot_detector/VOC2007_Test/JPEGImages/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/purva/Desktop/purva/ssd/input/detection_results\n",
      "/home/purva/Desktop/purva/ssd/input/ground_truth\n"
     ]
    }
   ],
   "source": [
    "print(DR_PATH)\n",
    "print(GT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4636"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=\"/home/purva/Desktop/purva/ssd/input/detection_results/\"\n",
    "list_=[]\n",
    "import os\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith(\".txt\"):\n",
    "        list_.append(os.path.join(path, file))\n",
    "len(list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in list_:\n",
    "    fh = open(file, \"r\")\n",
    "    lines = fh.readlines()\n",
    "    fh.close()\n",
    "    if lines==[]:\n",
    "        a=a+1\n",
    "        os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/purva/Desktop/purva/ssd/input/ground_truth'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total ground-truth files: 4636\n",
      "total detection-results files: 4636\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.chdir(GT_PATH)\n",
    "gt_files = glob.glob('*.txt')\n",
    "if len(gt_files) == 0:\n",
    "    print(\"Error: no .txt files found in\", GT_PATH)\n",
    "    \n",
    "os.chdir(DR_PATH)\n",
    "dr_files = glob.glob('*.txt')\n",
    "if len(dr_files) == 0:\n",
    "    print(\"Error: no .txt files found in\", DR_PATH)\n",
    "    \n",
    "gt_files = set(gt_files)\n",
    "dr_files = set(dr_files)\n",
    "print('total ground-truth files:', len(gt_files))\n",
    "print('total detection-results files:', len(dr_files))\n",
    "print()\n",
    "backup_folder = 'backup_no_matches_found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No backup required for /home/purva/Desktop/purva/ssd/input/ground_truth\n",
      "No backup required for /home/purva/Desktop/purva/ssd/input/detection_results\n",
      "total intersected files: 4636\n",
      "Intersection completed!\n"
     ]
    }
   ],
   "source": [
    "gt_backup = gt_files - dr_files\n",
    "dr_backup = dr_files - gt_files\n",
    "\n",
    "def backup(src_folder, backup_files, backup_folder):\n",
    "    # non-intersection files (txt format) will be moved to a backup folder\n",
    "    if not backup_files:\n",
    "        print('No backup required for', src_folder)\n",
    "        return\n",
    "    os.chdir(src_folder)\n",
    "    ## create the backup dir if it doesn't exist already\n",
    "    if not os.path.exists(backup_folder):\n",
    "        os.makedirs(backup_folder)\n",
    "    for file in backup_files:\n",
    "        os.rename(file, backup_folder + '/' + file)\n",
    "    \n",
    "backup(GT_PATH, gt_backup, backup_folder)\n",
    "backup(DR_PATH, dr_backup, backup_folder)\n",
    "if gt_backup:\n",
    "    print('total ground-truth backup files:', len(gt_backup))\n",
    "if dr_backup:\n",
    "    print('total detection-results backup files:', len(dr_backup))\n",
    "\n",
    "intersection = gt_files & dr_files\n",
    "print('total intersected files:', len(intersection))\n",
    "print(\"Intersection completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/purva/Desktop/purva/ssd/input/ground_truth'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GT_PATH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH = '/home/purva/Desktop/purva/Single_shot_detector/VOC2007_Test/JPEGImages/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import operator\n",
    "import sys\n",
    "import argparse\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "MINOVERLAP = 0.5 # default value (defined in the PASCAL VOC2012 challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_animation = True\n",
    "show_animation= False\n",
    "import matplotlib.pyplot as plt\n",
    "draw_plot = True\n",
    "no_plot = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_average_miss_rate(precision, fp_cumsum, num_images):\n",
    "    \n",
    "    if precision.size == 0:\n",
    "        lamr = 0\n",
    "        mr = 1\n",
    "        fppi = 0\n",
    "        return lamr, mr, fppi\n",
    "\n",
    "    fppi = fp_cumsum / float(num_images)\n",
    "    mr = (1 - precision)\n",
    "\n",
    "    fppi_tmp = np.insert(fppi, 0, -1.0)\n",
    "    mr_tmp = np.insert(mr, 0, 1.0)\n",
    "\n",
    "    # Use 9 evenly spaced reference points in log-space\n",
    "    ref = np.logspace(-2.0, 0.0, num = 9)\n",
    "    for i, ref_i in enumerate(ref):\n",
    "        # np.where() will always find at least 1 index, since min(ref) = 0.01 and min(fppi_tmp) = -1.0\n",
    "        j = np.where(fppi_tmp <= ref_i)[-1][-1]\n",
    "        ref[i] = mr_tmp[j]\n",
    "\n",
    "    # log(0) is undefined, so we use the np.maximum(1e-10, ref)\n",
    "    lamr = math.exp(np.mean(np.log(np.maximum(1e-10, ref))))\n",
    "\n",
    "    return lamr, mr, fppi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(msg):\n",
    "    print(msg)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_float_between_0_and_1(value):\n",
    "    try:\n",
    "        val = float(value)\n",
    "        if val > 0.0 and val < 1.0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voc_ap(rec, prec):\n",
    "    \"\"\"\n",
    "    --- Official matlab code VOC2012---\n",
    "    mrec=[0 ; rec ; 1];\n",
    "    mpre=[0 ; prec ; 0];\n",
    "    for i=numel(mpre)-1:-1:1\n",
    "            mpre(i)=max(mpre(i),mpre(i+1));\n",
    "    end\n",
    "    i=find(mrec(2:end)~=mrec(1:end-1))+1;\n",
    "    ap=sum((mrec(i)-mrec(i-1)).*mpre(i));\n",
    "    \"\"\"\n",
    "    rec.insert(0, 0.0) # insert 0.0 at begining of list\n",
    "    rec.append(1.0) # insert 1.0 at end of list\n",
    "    mrec = rec[:]\n",
    "    prec.insert(0, 0.0) # insert 0.0 at begining of list\n",
    "    prec.append(0.0) # insert 0.0 at end of list\n",
    "    mpre = prec[:]\n",
    "    \"\"\"\n",
    "     This part makes the precision monotonically decreasing\n",
    "        (goes from the end to the beginning)\n",
    "        matlab: for i=numel(mpre)-1:-1:1\n",
    "                    mpre(i)=max(mpre(i),mpre(i+1));\n",
    "    \"\"\"\n",
    "    # matlab indexes start in 1 but python in 0, so I have to do:\n",
    "    #     range(start=(len(mpre) - 2), end=0, step=-1)\n",
    "    # also the python function range excludes the end, resulting in:\n",
    "    #     range(start=(len(mpre) - 2), end=-1, step=-1)\n",
    "    for i in range(len(mpre)-2, -1, -1):\n",
    "        mpre[i] = max(mpre[i], mpre[i+1])\n",
    "    \"\"\"\n",
    "     This part creates a list of indexes where the recall changes\n",
    "        matlab: i=find(mrec(2:end)~=mrec(1:end-1))+1;\n",
    "    \"\"\"\n",
    "    i_list = []\n",
    "    for i in range(1, len(mrec)):\n",
    "        if mrec[i] != mrec[i-1]:\n",
    "            i_list.append(i) # if it was matlab would be i + 1\n",
    "    \"\"\"\n",
    "     The Average Precision (AP) is the area under the curve\n",
    "        (numerical integration)\n",
    "        matlab: ap=sum((mrec(i)-mrec(i-1)).*mpre(i));\n",
    "    \"\"\"\n",
    "    ap = 0.0\n",
    "    for i in i_list:\n",
    "        ap += ((mrec[i]-mrec[i-1])*mpre[i])\n",
    "    return ap, mrec, mpre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_lines_to_list(path):\n",
    "    # open txt file lines to a list\n",
    "    with open(path) as f:\n",
    "        content = f.readlines()\n",
    "    # remove whitespace characters like `\\n` at the end of each line\n",
    "    content = [x.strip() for x in content]\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_axes(r, t, fig, axes):\n",
    "    # get text width for re-scaling\n",
    "    bb = t.get_window_extent(renderer=r)\n",
    "    text_width_inches = bb.width / fig.dpi\n",
    "    # get axis width in inches\n",
    "    current_fig_width = fig.get_figwidth()\n",
    "    new_fig_width = current_fig_width + text_width_inches\n",
    "    propotion = new_fig_width / current_fig_width\n",
    "    # get axis limit\n",
    "    x_lim = axes.get_xlim()\n",
    "    axes.set_xlim([x_lim[0], x_lim[1]*propotion])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_text_in_image(img, text, pos, color, line_width):\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    fontScale = 1\n",
    "    lineType = 1\n",
    "    bottomLeftCornerOfText = pos\n",
    "    cv2.putText(img, text,\n",
    "            bottomLeftCornerOfText,\n",
    "            font,\n",
    "            fontScale,\n",
    "            color,\n",
    "            lineType)\n",
    "    text_width, _ = cv2.getTextSize(text, font, fontScale, lineType)[0]\n",
    "    return img, (line_width + text_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_axes(r, t, fig, axes):\n",
    "    # get text width for re-scaling\n",
    "    bb = t.get_window_extent(renderer=r)\n",
    "    text_width_inches = bb.width / fig.dpi\n",
    "    # get axis width in inches\n",
    "    current_fig_width = fig.get_figwidth()\n",
    "    new_fig_width = current_fig_width + text_width_inches\n",
    "    propotion = new_fig_width / current_fig_width\n",
    "    # get axis limit\n",
    "    x_lim = axes.get_xlim()\n",
    "    axes.set_xlim([x_lim[0], x_lim[1]*propotion])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_text_in_image(img, text, pos, color, line_width):\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    fontScale = 1\n",
    "    lineType = 1\n",
    "    bottomLeftCornerOfText = pos\n",
    "    cv2.putText(img, text,\n",
    "            bottomLeftCornerOfText,\n",
    "            font,\n",
    "            fontScale,\n",
    "            color,\n",
    "            lineType)\n",
    "    text_width, _ = cv2.getTextSize(text, font, fontScale, lineType)[0]\n",
    "    return img, (line_width + text_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_plot_func(dictionary, n_classes, window_title, plot_title, x_label, output_path, to_show, plot_color, true_p_bar):\n",
    "    # sort the dictionary by decreasing value, into a list of tuples\n",
    "    sorted_dic_by_value = sorted(dictionary.items(), key=operator.itemgetter(1))\n",
    "    # unpacking the list of tuples into two lists\n",
    "    sorted_keys, sorted_values = zip(*sorted_dic_by_value)\n",
    "    # \n",
    "    if true_p_bar != \"\":\n",
    "        \"\"\"\n",
    "         Special case to draw in:\n",
    "            - green -> TP: True Positives (object detected and matches ground-truth)\n",
    "            - red -> FP: False Positives (object detected but does not match ground-truth)\n",
    "            - orange -> FN: False Negatives (object not detected but present in the ground-truth)\n",
    "        \"\"\"\n",
    "        fp_sorted = []\n",
    "        tp_sorted = []\n",
    "        for key in sorted_keys:\n",
    "            fp_sorted.append(dictionary[key] - true_p_bar[key])\n",
    "            tp_sorted.append(true_p_bar[key])\n",
    "        plt.barh(range(n_classes), fp_sorted, align='center', color='crimson', label='False Positive')\n",
    "        plt.barh(range(n_classes), tp_sorted, align='center', color='forestgreen', label='True Positive', left=fp_sorted)\n",
    "        # add legend\n",
    "        plt.legend(loc='lower right')\n",
    "        \"\"\"\n",
    "         Write number on side of bar\n",
    "        \"\"\"\n",
    "        fig = plt.gcf() # gcf - get current figure\n",
    "        axes = plt.gca()\n",
    "        r = fig.canvas.get_renderer()\n",
    "        for i, val in enumerate(sorted_values):\n",
    "            fp_val = fp_sorted[i]\n",
    "            tp_val = tp_sorted[i]\n",
    "            fp_str_val = \" \" + str(fp_val)\n",
    "            tp_str_val = fp_str_val + \" \" + str(tp_val)\n",
    "            # trick to paint multicolor with offset:\n",
    "            # first paint everything and then repaint the first number\n",
    "            t = plt.text(val, i, tp_str_val, color='forestgreen', va='center', fontweight='bold')\n",
    "            plt.text(val, i, fp_str_val, color='crimson', va='center', fontweight='bold')\n",
    "            if i == (len(sorted_values)-1): # largest bar\n",
    "                adjust_axes(r, t, fig, axes)\n",
    "    else:\n",
    "        plt.barh(range(n_classes), sorted_values, color=plot_color)\n",
    "        \"\"\"\n",
    "         Write number on side of bar\n",
    "        \"\"\"\n",
    "        fig = plt.gcf() # gcf - get current figure\n",
    "        axes = plt.gca()\n",
    "        r = fig.canvas.get_renderer()\n",
    "        for i, val in enumerate(sorted_values):\n",
    "            str_val = \" \" + str(val) # add a space before\n",
    "            if val < 1.0:\n",
    "                str_val = \" {0:.2f}\".format(val)\n",
    "            t = plt.text(val, i, str_val, color=plot_color, va='center', fontweight='bold')\n",
    "            # re-set axes to show number inside the figure\n",
    "            if i == (len(sorted_values)-1): # largest bar\n",
    "                adjust_axes(r, t, fig, axes)\n",
    "    # set window title\n",
    "    fig.canvas.set_window_title(window_title)\n",
    "    # write classes in y axis\n",
    "    tick_font_size = 12\n",
    "    plt.yticks(range(n_classes), sorted_keys, fontsize=tick_font_size)\n",
    "    \"\"\"\n",
    "     Re-scale height accordingly\n",
    "    \"\"\"\n",
    "    init_height = fig.get_figheight()\n",
    "    # comput the matrix height in points and inches\n",
    "    dpi = fig.dpi\n",
    "    height_pt = n_classes * (tick_font_size * 1.4) # 1.4 (some spacing)\n",
    "    height_in = height_pt / dpi\n",
    "    # compute the required figure height \n",
    "    top_margin = 0.15 # in percentage of the figure height\n",
    "    bottom_margin = 0.05 # in percentage of the figure height\n",
    "    figure_height = height_in / (1 - top_margin - bottom_margin)\n",
    "    # set new height\n",
    "    if figure_height > init_height:\n",
    "        fig.set_figheight(figure_height)\n",
    "\n",
    "    # set plot title\n",
    "    plt.title(plot_title, fontsize=14)\n",
    "    # set axis titles\n",
    "    # plt.xlabel('classes')\n",
    "    plt.xlabel(x_label, fontsize='large')\n",
    "    # adjust size of window\n",
    "    fig.tight_layout()\n",
    "    # save the plot\n",
    "    fig.savefig(output_path)\n",
    "    # show image\n",
    "    if to_show:\n",
    "        plt.show()\n",
    "    # close the plot\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/purva/Desktop/purva/ssd/input/detection_results'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMP_FILES_PATH = \".temp_files\"\n",
    "if not os.path.exists(TEMP_FILES_PATH): # if it doesn't exist already\n",
    "    os.makedirs(TEMP_FILES_PATH)\n",
    "results_files_path =\"/home/purva/Desktop/purva/ssd/input/detection_results/results\"\n",
    "if not os.path.exists(results_files_path): # if it doesn't exist already\n",
    "    os.makedirs(results_files_path)\n",
    "if os.path.exists(results_files_path): # if it exist already\n",
    "    # reset the results directory\n",
    "    shutil.rmtree(results_files_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/purva/Desktop/purva/ssd/input/detection_results/.temp_files'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.abspath(TEMP_FILES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(results_files_path)\n",
    "if draw_plot:\n",
    "    os.makedirs(os.path.join(results_files_path, \"classes\"))\n",
    "if show_animation:\n",
    "    os.makedirs(os.path.join(results_files_path, \"images\", \"detections_one_by_one\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/purva/Desktop/purva/ssd/input/detection_results/.temp_files'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.abspath(TEMP_FILES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_path = os.path.join(results_files_path, \"classes\")\n",
    "if draw_plot:\n",
    "    if not os.path.exists(class_path):\n",
    "        os.makedirs(class_path)\n",
    "        \n",
    "        \n",
    "animation_path = os.path.join(results_files_path, \"images\", \"detections_one_by_one\")\n",
    "\n",
    "if show_animation:\n",
    "    if not os.path.exists(class_path):\n",
    "        os.makedirs(animation_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_files_list = glob.glob(GT_PATH + '/*.txt')\n",
    "if len(ground_truth_files_list) == 0:\n",
    "    error(\"Error: No ground-truth files found!\")\n",
    "ground_truth_files_list.sort()\n",
    "# dictionary with counter per class\n",
    "gt_counter_per_class = {}\n",
    "counter_images_per_class = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog 48 240 195 371', 'person 8 12 352 498']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_file=ground_truth_files_list[0]\n",
    "file_id = txt_file.split(\".txt\", 1)[0]\n",
    "file_id = os.path.basename(os.path.normpath(file_id))\n",
    "temp_path = os.path.join(DR_PATH, (file_id + \".txt\"))\n",
    "\n",
    "lines_list = file_lines_to_list(txt_file)\n",
    "lines_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "for txt_file in ground_truth_files_list:\n",
    "    #print(txt_file)\n",
    "    file_id = txt_file.split(\".txt\", 1)[0]\n",
    "    file_id = os.path.basename(os.path.normpath(file_id))\n",
    "    # check if there is a correspondent detection-results file\n",
    "    temp_path = os.path.join(DR_PATH, (file_id + \".txt\"))\n",
    "    if not os.path.exists(temp_path):\n",
    "        error_msg = \"Error. File not found: {}\\n\".format(temp_path)\n",
    "        error_msg += \"(You can avoid this error message by running extra/intersect-gt-and-dr.py)\"\n",
    "        error(error_msg)\n",
    "    lines_list = file_lines_to_list(txt_file)\n",
    "    # create ground-truth dictionary\n",
    "    bounding_boxes = []\n",
    "    is_difficult = False\n",
    "    already_seen_classes = []\n",
    "    for line in lines_list:\n",
    "        try:\n",
    "            if \"difficult\" in line:\n",
    "                    class_name, left, top, right, bottom, _difficult = line.split()\n",
    "                    is_difficult = True\n",
    "            else:\n",
    "                    class_name, left, top, right, bottom = line.split()\n",
    "        except ValueError:\n",
    "            error_msg = \"Error: File \" + txt_file + \" in the wrong format.\\n\"\n",
    "            error_msg += \" Expected: <class_name> <left> <top> <right> <bottom> ['difficult']\\n\"\n",
    "            error_msg += \" Received: \" + line\n",
    "            error_msg += \"\\n\\nIf you have a <class_name> with spaces between words you should remove them\\n\"\n",
    "            error_msg += \"by running the script \\\"remove_space.py\\\" or \\\"rename_class.py\\\" in the \\\"extra/\\\" folder.\"\n",
    "            error(error_msg)\n",
    "        # check if class is in the ignore list, if yes skip\n",
    "        if class_name in ignore:\n",
    "            continue\n",
    "        bbox = left + \" \" + top + \" \" + right + \" \" +bottom\n",
    "        if is_difficult:\n",
    "                bounding_boxes.append({\"class_name\":class_name, \"bbox\":bbox, \"used\":False, \"difficult\":True})\n",
    "                is_difficult = False\n",
    "        else:\n",
    "                bounding_boxes.append({\"class_name\":class_name, \"bbox\":bbox, \"used\":False})\n",
    "                # count that object\n",
    "                if class_name in gt_counter_per_class:\n",
    "                    gt_counter_per_class[class_name] += 1\n",
    "                else:\n",
    "                    # if class didn't exist yet\n",
    "                    gt_counter_per_class[class_name] = 1\n",
    "\n",
    "                if class_name not in already_seen_classes:\n",
    "                    if class_name in counter_images_per_class:\n",
    "                        counter_images_per_class[class_name] += 1\n",
    "                    else:\n",
    "                        # if class didn't exist yet\n",
    "                        counter_images_per_class[class_name] = 1\n",
    "                    already_seen_classes.append(class_name)\n",
    "\n",
    "\n",
    "    # dump bounding_boxes into a \".json\" file\n",
    "    with open(TEMP_FILES_PATH + \"/\" + file_id + \"_ground_truth.json\", 'w') as outfile:\n",
    "        json.dump(bounding_boxes, outfile)\n",
    "gt_classes = list(gt_counter_per_class.keys())\n",
    "gt_classes = sorted(gt_classes)\n",
    "n_classes = len(gt_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_files_list = glob.glob(DR_PATH + '/*.txt')\n",
    "dr_files_list.sort()\n",
    "for class_index, class_name in enumerate(gt_classes):\n",
    "    bounding_boxes = []\n",
    "    for txt_file in dr_files_list:\n",
    "        #print(txt_file)\n",
    "        # the first time it checks if all the corresponding ground-truth files exist\n",
    "        file_id = txt_file.split(\".txt\",1)[0]\n",
    "        file_id = os.path.basename(os.path.normpath(file_id))\n",
    "        temp_path = os.path.join(GT_PATH, (file_id + \".txt\"))\n",
    "        if class_index == 0:\n",
    "            if not os.path.exists(temp_path):\n",
    "                error_msg = \"Error. File not found: {}\\n\".format(temp_path)\n",
    "                error_msg += \"(You can avoid this error message by running extra/intersect-gt-and-dr.py)\"\n",
    "                error(error_msg)\n",
    "        lines = file_lines_to_list(txt_file)\n",
    "        for line in lines:\n",
    "            try:\n",
    "                tmp_class_name, confidence, left, top, right, bottom = line.split()\n",
    "            except ValueError:\n",
    "                error_msg = \"Error: File \" + txt_file + \" in the wrong format.\\n\"\n",
    "                error_msg += \" Expected: <class_name> <confidence> <left> <top> <right> <bottom>\\n\"\n",
    "                error_msg += \" Received: \" + line\n",
    "                error(error_msg)\n",
    "            if tmp_class_name == class_name:\n",
    "                #print(\"match\")\n",
    "                bbox = left + \" \" + top + \" \" + right + \" \" +bottom\n",
    "                bounding_boxes.append({\"confidence\":confidence, \"file_id\":file_id, \"bbox\":bbox})\n",
    "                #print(bounding_boxes)\n",
    "    # sort detection-results by decreasing confidence\n",
    "    bounding_boxes.sort(key=lambda x:float(x['confidence']), reverse=True)\n",
    "    with open(TEMP_FILES_PATH + \"/\" + class_name + \"_dr.json\", 'w') as outfile:\n",
    "        json.dump(bounding_boxes, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train'"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_file=dr_files_list[1]\n",
    "file_id = txt_file.split(\".txt\",1)[0]\n",
    "file_id = os.path.basename(os.path.normpath(file_id))\n",
    "temp_path = os.path.join(GT_PATH, (file_id + \".txt\"))\n",
    "lines = file_lines_to_list(txt_file)\n",
    "for line in lines:\n",
    "    tmp_class_name, confidence, left, top, right, bottom = line.split()\n",
    "tmp_class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.81% = aeroplane AP \n",
      "56.67% = bicycle AP \n",
      "51.05% = bird AP \n",
      "36.47% = boat AP \n",
      "12.36% = bottle AP \n",
      "64.19% = bus AP \n",
      "60.80% = car AP \n",
      "79.03% = cat AP \n",
      "22.55% = chair AP \n",
      "45.12% = cow AP \n",
      "49.76% = diningtable AP \n",
      "64.91% = dog AP \n",
      "69.61% = horse AP \n",
      "52.20% = motorbike AP \n",
      "45.60% = person AP \n",
      "30.36% = pottedplant AP \n",
      "44.17% = sheep AP \n",
      "52.13% = sofa AP \n",
      "78.92% = train AP \n",
      "58.15% = tvmonitor AP \n",
      "mAP = 52.14%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "sum_AP = 0.0\n",
    "ap_dictionary = {}\n",
    "lamr_dictionary = {}\n",
    "# open file to store the results\n",
    "with open(results_files_path + \"/results.txt\", 'w') as results_file:\n",
    "    results_file.write(\"# AP and precision/recall per class\\n\")\n",
    "    count_true_positives = {}\n",
    "    for class_index, class_name in enumerate(gt_classes):\n",
    "        count_true_positives[class_name] = 0\n",
    "        \"\"\"\n",
    "         Load detection-results of that class\n",
    "        \"\"\"\n",
    "        dr_file = TEMP_FILES_PATH + \"/\" + class_name + \"_dr.json\"\n",
    "        dr_data = json.load(open(dr_file))\n",
    "\n",
    "        \"\"\"\n",
    "         Assign detection-results to ground-truth objects\n",
    "        \"\"\"\n",
    "        nd = len(dr_data)\n",
    "        tp = [0] * nd # creates an array of zeros of size nd\n",
    "        fp = [0] * nd\n",
    "        for idx, detection in enumerate(dr_data):\n",
    "            file_id = detection[\"file_id\"]\n",
    "            if show_animation:\n",
    "                # find ground truth image\n",
    "                ground_truth_img = glob.glob1(IMG_PATH, file_id + \".*\")\n",
    "                #tifCounter = len(glob.glob1(myPath,\"*.tif\"))\n",
    "                if len(ground_truth_img) == 0:\n",
    "                    error(\"Error. Image not found with id: \" + file_id)\n",
    "                elif len(ground_truth_img) > 1:\n",
    "                    error(\"Error. Multiple image with id: \" + file_id)\n",
    "                else: # found image\n",
    "                    #print(IMG_PATH + \"/\" + ground_truth_img[0])\n",
    "                    # Load image\n",
    "                    img = cv2.imread(IMG_PATH + \"/\" + ground_truth_img[0])\n",
    "                    # load image with draws of multiple detections\n",
    "                    img_cumulative_path = results_files_path + \"/images/\" + ground_truth_img[0]\n",
    "                    if os.path.isfile(img_cumulative_path):\n",
    "                        img_cumulative = cv2.imread(img_cumulative_path)\n",
    "                    else:\n",
    "                        img_cumulative = img.copy()\n",
    "                    # Add bottom border to image\n",
    "                    bottom_border = 60\n",
    "                    BLACK = [0, 0, 0]\n",
    "                    img = cv2.copyMakeBorder(img, 0, bottom_border, 0, 0, cv2.BORDER_CONSTANT, value=BLACK)\n",
    "            # assign detection-results to ground truth object if any\n",
    "            # open ground-truth with that file_id\n",
    "            gt_file = TEMP_FILES_PATH + \"/\" + file_id + \"_ground_truth.json\"\n",
    "            ground_truth_data = json.load(open(gt_file))\n",
    "            ovmax = -1\n",
    "            gt_match = -1\n",
    "            # load detected object bounding-box\n",
    "            bb = [ float(x) for x in detection[\"bbox\"].split() ]\n",
    "            for obj in ground_truth_data:\n",
    "                # look for a class_name match\n",
    "                if obj[\"class_name\"] == class_name:\n",
    "                    bbgt = [ float(x) for x in obj[\"bbox\"].split() ]\n",
    "                    bi = [max(bb[0],bbgt[0]), max(bb[1],bbgt[1]), min(bb[2],bbgt[2]), min(bb[3],bbgt[3])]\n",
    "                    iw = bi[2] - bi[0] + 1\n",
    "                    ih = bi[3] - bi[1] + 1\n",
    "                    if iw > 0 and ih > 0:\n",
    "                        # compute overlap (IoU) = area of intersection / area of union\n",
    "                        ua = (bb[2] - bb[0] + 1) * (bb[3] - bb[1] + 1) + (bbgt[2] - bbgt[0]\n",
    "                                        + 1) * (bbgt[3] - bbgt[1] + 1) - iw * ih\n",
    "                        ov = iw * ih / ua\n",
    "                        if ov > ovmax:\n",
    "                            ovmax = ov\n",
    "                            gt_match = obj\n",
    "\n",
    "            # assign detection as true positive/don't care/false positive\n",
    "            if show_animation:\n",
    "                status = \"NO MATCH FOUND!\" # status is only used in the animation\n",
    "            # set minimum overlap\n",
    "            min_overlap = MINOVERLAP\n",
    "            if specific_iou_flagged:\n",
    "                if class_name in specific_iou_classes:\n",
    "                    index = specific_iou_classes.index(class_name)\n",
    "                    min_overlap = float(iou_list[index])\n",
    "            if ovmax >= min_overlap:\n",
    "                if \"difficult\" not in gt_match:\n",
    "                        if not bool(gt_match[\"used\"]):\n",
    "                            # true positive\n",
    "                            tp[idx] = 1\n",
    "                            gt_match[\"used\"] = True\n",
    "                            count_true_positives[class_name] += 1\n",
    "                            # update the \".json\" file\n",
    "                            with open(gt_file, 'w') as f:\n",
    "                                    f.write(json.dumps(ground_truth_data))\n",
    "                            if show_animation:\n",
    "                                status = \"MATCH!\"\n",
    "                        else:\n",
    "                            # false positive (multiple detection)\n",
    "                            fp[idx] = 1\n",
    "                            if show_animation:\n",
    "                                status = \"REPEATED MATCH!\"\n",
    "            else:\n",
    "                # false positive\n",
    "                fp[idx] = 1\n",
    "                if ovmax > 0:\n",
    "                    status = \"INSUFFICIENT OVERLAP\"\n",
    "\n",
    "            \"\"\"\n",
    "             Draw image to show animation\n",
    "            \"\"\"\n",
    "            if show_animation:\n",
    "                height, widht = img.shape[:2]\n",
    "                # colors (OpenCV works with BGR)\n",
    "                white = (255,255,255)\n",
    "                light_blue = (255,200,100)\n",
    "                green = (0,255,0)\n",
    "                light_red = (30,30,255)\n",
    "                # 1st line\n",
    "                margin = 10\n",
    "                v_pos = int(height - margin - (bottom_border / 2.0))\n",
    "                text = \"Image: \" + ground_truth_img[0] + \" \"\n",
    "                img, line_width = draw_text_in_image(img, text, (margin, v_pos), white, 0)\n",
    "                text = \"Class [\" + str(class_index) + \"/\" + str(n_classes) + \"]: \" + class_name + \" \"\n",
    "                img, line_width = draw_text_in_image(img, text, (margin + line_width, v_pos), light_blue, line_width)\n",
    "                if ovmax != -1:\n",
    "                    color = light_red\n",
    "                    if status == \"INSUFFICIENT OVERLAP\":\n",
    "                        text = \"IoU: {0:.2f}% \".format(ovmax*100) + \"< {0:.2f}% \".format(min_overlap*100)\n",
    "                    else:\n",
    "                        text = \"IoU: {0:.2f}% \".format(ovmax*100) + \">= {0:.2f}% \".format(min_overlap*100)\n",
    "                        color = green\n",
    "                    img, _ = draw_text_in_image(img, text, (margin + line_width, v_pos), color, line_width)\n",
    "                # 2nd line\n",
    "                v_pos += int(bottom_border / 2.0)\n",
    "                rank_pos = str(idx+1) # rank position (idx starts at 0)\n",
    "                text = \"Detection #rank: \" + rank_pos + \" confidence: {0:.2f}% \".format(float(detection[\"confidence\"])*100)\n",
    "                img, line_width = draw_text_in_image(img, text, (margin, v_pos), white, 0)\n",
    "                color = light_red\n",
    "                if status == \"MATCH!\":\n",
    "                    color = green\n",
    "                text = \"Result: \" + status + \" \"\n",
    "                img, line_width = draw_text_in_image(img, text, (margin + line_width, v_pos), color, line_width)\n",
    "\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                if ovmax > 0: # if there is intersections between the bounding-boxes\n",
    "                    bbgt = [ int(round(float(x))) for x in gt_match[\"bbox\"].split() ]\n",
    "                    cv2.rectangle(img,(bbgt[0],bbgt[1]),(bbgt[2],bbgt[3]),light_blue,2)\n",
    "                    cv2.rectangle(img_cumulative,(bbgt[0],bbgt[1]),(bbgt[2],bbgt[3]),light_blue,2)\n",
    "                    cv2.putText(img_cumulative, class_name, (bbgt[0],bbgt[1] - 5), font, 0.6, light_blue, 1, cv2.LINE_AA)\n",
    "                bb = [int(i) for i in bb]\n",
    "                cv2.rectangle(img,(bb[0],bb[1]),(bb[2],bb[3]),color,2)\n",
    "                cv2.rectangle(img_cumulative,(bb[0],bb[1]),(bb[2],bb[3]),color,2)\n",
    "                cv2.putText(img_cumulative, class_name, (bb[0],bb[1] - 5), font, 0.6, color, 1, cv2.LINE_AA)\n",
    "                # show image\n",
    "                cv2.imshow(\"Animation\", img)\n",
    "                cv2.waitKey(20) # show for 20 ms\n",
    "                # save image to results\n",
    "                output_img_path = results_files_path + \"/images/detections_one_by_one/\" + class_name + \"_detection\" + str(idx) + \".jpg\"\n",
    "                cv2.imwrite(output_img_path, img)\n",
    "                # save the image with all the objects drawn to it\n",
    "                cv2.imwrite(img_cumulative_path, img_cumulative)\n",
    "\n",
    "        #print(tp)\n",
    "        # compute precision/recall\n",
    "        cumsum = 0\n",
    "        for idx, val in enumerate(fp):\n",
    "            fp[idx] += cumsum\n",
    "            cumsum += val\n",
    "        cumsum = 0\n",
    "        for idx, val in enumerate(tp):\n",
    "            tp[idx] += cumsum\n",
    "            cumsum += val\n",
    "        #print(tp)\n",
    "        rec = tp[:]\n",
    "        for idx, val in enumerate(tp):\n",
    "            rec[idx] = float(tp[idx]) / gt_counter_per_class[class_name]\n",
    "        #print(rec)\n",
    "        prec = tp[:]\n",
    "        for idx, val in enumerate(tp):\n",
    "            prec[idx] = float(tp[idx]) / (fp[idx] + tp[idx])\n",
    "        #print(prec)\n",
    "\n",
    "        ap, mrec, mprec = voc_ap(rec[:], prec[:])\n",
    "        sum_AP += ap\n",
    "        text = \"{0:.2f}%\".format(ap*100) + \" = \" + class_name + \" AP \" #class_name + \" AP = {0:.2f}%\".format(ap*100)\n",
    "        \"\"\"\n",
    "         Write to results.txt\n",
    "        \"\"\"\n",
    "        rounded_prec = [ '%.2f' % elem for elem in prec ]\n",
    "        rounded_rec = [ '%.2f' % elem for elem in rec ]\n",
    "        results_file.write(text + \"\\n Precision: \" + str(rounded_prec) + \"\\n Recall :\" + str(rounded_rec) + \"\\n\\n\")\n",
    "        print(text)\n",
    "        ap_dictionary[class_name] = ap\n",
    "\n",
    "        n_images = counter_images_per_class[class_name]\n",
    "        lamr, mr, fppi = log_average_miss_rate(np.array(rec), np.array(fp), n_images)\n",
    "        lamr_dictionary[class_name] = lamr\n",
    "\n",
    "        \"\"\"\n",
    "         Draw plot\n",
    "        \"\"\"\n",
    "        if draw_plot:\n",
    "            plt.plot(rec, prec, '-o')\n",
    "            # add a new penultimate point to the list (mrec[-2], 0.0)\n",
    "            # since the last line segment (and respective area) do not affect the AP value\n",
    "            area_under_curve_x = mrec[:-1] + [mrec[-2]] + [mrec[-1]]\n",
    "            area_under_curve_y = mprec[:-1] + [0.0] + [mprec[-1]]\n",
    "            plt.fill_between(area_under_curve_x, 0, area_under_curve_y, alpha=0.2, edgecolor='r')\n",
    "            # set window title\n",
    "            fig = plt.gcf() # gcf - get current figure\n",
    "            fig.canvas.set_window_title('AP ' + class_name)\n",
    "            # set plot title\n",
    "            plt.title('class: ' + text)\n",
    "            #plt.suptitle('This is a somewhat long figure title', fontsize=16)\n",
    "            # set axis titles\n",
    "            plt.xlabel('Recall')\n",
    "            plt.ylabel('Precision')\n",
    "            # optional - set axes\n",
    "            axes = plt.gca() # gca - get current axes\n",
    "            axes.set_xlim([0.0,1.0])\n",
    "            axes.set_ylim([0.0,1.05]) # .05 to give some extra space\n",
    "            # Alternative option -> wait for button to be pressed\n",
    "            #while not plt.waitforbuttonpress(): pass # wait for key display\n",
    "            # Alternative option -> normal display\n",
    "            #plt.show()\n",
    "            # save the plot\n",
    "            fig.savefig(results_files_path + \"/classes/\" + class_name + \".png\")\n",
    "            plt.cla() # clear axes for next plot\n",
    "\n",
    "    if show_animation:\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    results_file.write(\"\\n# mAP of all classes\\n\")\n",
    "    mAP = sum_AP / n_classes\n",
    "    text = \"mAP = {0:.2f}%\".format(mAP*100)\n",
    "    results_file.write(text + \"\\n\")\n",
    "    print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
